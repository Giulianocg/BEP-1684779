{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "b66f5614",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---sex---\n",
      "---cp---\n",
      "---fbs---\n",
      "---restecg---\n",
      "---exang---\n",
      "---slope---\n",
      "---thal---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib import figure\n",
    "import numpy as np\n",
    "import random \n",
    "from decimal import Decimal\n",
    "from math import ceil, floor, pow\n",
    "import pickle\n",
    "\n",
    "##########################################################################################################\n",
    "  \n",
    "#function to count significant figures\n",
    "def count_sigfigs(numstr):\n",
    "    return len(Decimal(numstr).normalize().as_tuple().digits)\n",
    "\n",
    "##########################################################################################################  \n",
    "    \n",
    "def prep_data3(ID, Round, Norm=False):\n",
    "    ''' Drops NaN and empty columns, binarizes ALL categorical data\n",
    "    \n",
    "    ID    : Integer. ID of the database, taken from the UCI repository\n",
    "    Norm  : Boolean. If true, features are normalized at the beggining to match max and min values\n",
    "    Round : Integer. Rounds values to that many significant figures, is they need to.\n",
    "    '''\n",
    "    \n",
    "    database = fetch_ucirepo(id=ID) \n",
    "    X = database.data.features #dataframes by default\n",
    "    y = database.data.targets \n",
    "\n",
    "    #delete 'nan' and '?' rows\n",
    "    Data = X.dropna()\n",
    "    for j in range(len(Data.columns)):\n",
    "        if (Data.dtypes[j].name == 'object'): \n",
    "            col_name = Data.columns[j]\n",
    "            Data = Data[Data[col_name] != '?']\n",
    "\n",
    "    Y = y.iloc[Data.index]\n",
    "    Data = Data.reset_index(drop=True)\n",
    "    Y = Y.reset_index(drop=True)\n",
    "\n",
    "    if (ID==2):                                               #you need to set these ones mannually, they're all different\n",
    "        y = [int(i == '>50K.') for i in Y['income']]\n",
    "    elif (ID == 45):                                          #heart\n",
    "        mask = Data[Data['chol'] >= 500].index\n",
    "        \n",
    "        Data= Data.drop(mask)      #take out outsiders\n",
    "        Y = Y.drop(mask)\n",
    "        \n",
    "        Data = Data.reset_index(drop=True)\n",
    "        Y = Y.reset_index(drop=True)\n",
    "        \n",
    "        y = [i for i in Y['num']]\n",
    "        #y = [int(i != 0) for i in Y['num']]\n",
    "        \n",
    "        Data['ca'] = Data['ca'].astype(int)\n",
    "        Data['thal'] = Data['thal'].astype(int)\n",
    "    elif (ID==73):                                            #mushrooms\n",
    "        y = [int(i == 'p') for i in Y['poisonous']]\n",
    "    elif (ID==75):                                            #musk v2\n",
    "        y = [int(i) for i in Y['class']] \n",
    "    elif (ID==101):                                           #tictactoe                                         \n",
    "        y = [int(i == 'positive') for i in Y['class']]   \n",
    "    elif (ID==144):\n",
    "        y = [i-1 for i in Y['class']]\n",
    "\n",
    "\n",
    "\n",
    "    #binarize categorical data (with more than 2 categories)\n",
    "    info = database.variables\n",
    "    if (ID==101)|(ID==73):\n",
    "        info = info.drop(0, axis=0).reset_index()\n",
    "    elif (ID==75):\n",
    "        info = info.drop([0,1, 168], axis=0).reset_index()\n",
    "        \n",
    "    Ncols = len(info)\n",
    "\n",
    "    categ_col_list = [info['name'][i] for i in range(Ncols) if ((info['type'][i]=='Categorical') | (info['type'][i]=='Binary'))]\n",
    "    for col_name in categ_col_list: \n",
    "        print('---' + col_name +'---')\n",
    "\n",
    "        num_uniques = len(Data[col_name].unique())\n",
    "        if (num_uniques != 2):\n",
    "            for value in Data[col_name].unique():\n",
    "                new_col_name = 'Is ' + col_name + ' = ' + str(value)\n",
    "                New_Column = pd.DataFrame([n for n in [(Data[col_name] == value).astype(int)][0]], columns=[new_col_name])\n",
    "                Data = pd.concat([Data, New_Column], axis=1)\n",
    "            Data = Data.drop(col_name, axis=1)\n",
    "        elif (num_uniques == 2):\n",
    "            \n",
    "            value = Data[col_name].unique()[0]\n",
    "            new_col_name = 'Is ' + col_name + ' = ' + str(value)\n",
    "            New_Column = pd.DataFrame([n for n in [(Data[col_name] == value).astype(int)][0]], columns=[new_col_name])\n",
    "            Data = pd.concat([Data, New_Column], axis=1)\n",
    "            Data = Data.drop(col_name, axis=1)\n",
    "        else:\n",
    "            print('ERROR_Uniques')\n",
    "    #print(Data)       \n",
    "    #Scale columns to given s.f.\n",
    "    \n",
    "    #with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    #    print(Data)\n",
    "    \n",
    "    for col in Data.columns:  \n",
    "       \n",
    "        if (str(Data[col].dtype)[:5]=='float'):\n",
    "            precission = max([len(str(Data[col][i]).split('.')[1]) for i in range(len(Data))])\n",
    "            size =  max([len(str(Data[col][i]).split('.')[0]) for i in range(len(Data))])\n",
    "        elif (str(Data[col].dtype)[:3]=='int'):\n",
    "            precission = 0\n",
    "            size = max([len(str(Data[col][i])) for i in range(len(Data))])\n",
    "        \n",
    "        if (size + precission <= Round)&(precission > 0):\n",
    "            New_Column = pd.DataFrame([int(i*(10**precission)) for i in Data[col]], columns=[col+ ' 10^' + str(precission)])\n",
    "            Data = pd.concat([Data, New_Column], axis=1)\n",
    "            Data = Data.drop(col, axis=1)\n",
    "        elif (size + precission > Round):\n",
    "            expon = Round - size\n",
    "            New_Column = pd.DataFrame([round(i*(10**expon)) for i in Data[col]], columns=[col+ ' 10^' + str(expon)])\n",
    "            Data = pd.concat([Data, New_Column], axis=1)\n",
    "            Data = Data.drop(col, axis=1)\n",
    "    \n",
    "    \n",
    "    '''#normalize if chosen\n",
    "    #Keeps as many significant figures as needed to be able to un-do the normalization and not lose information \n",
    "    #(you'd need the un_norm dataframe to recover the innitial data)\n",
    "    if norm:\n",
    "        un_norm = pd.DataFrame()\n",
    "        for i in Data.columns:\n",
    "            col_max = max(Data[i])\n",
    "            col_min = min(Data[i])\n",
    "            col_range = col_max - col_min\n",
    "            \n",
    "            precis = max(count_sigfigs(str(col_range)), len(str(int(col_range))) )\n",
    "            dec_places = -Decimal(str(Data[i][0])).as_tuple().exponent\n",
    "            un_norm[i] = [col_range, col_min, int(precis), dec_places]\n",
    "            \n",
    "            Data[i] = [round( (j-col_min)/col_range, precis) for j in Data[i]]''' #skip this for now\n",
    "        \n",
    "    #turn it into a np array, we dont like pandas anymore :(\n",
    "    data_vals = Data.to_numpy()\n",
    "    data_cols = Data.columns.to_numpy()\n",
    "    \n",
    "    with open('Model_Script/Data/Data_vals_id_'+str(ID)+'.npy', 'wb') as f:\n",
    "        np.save(f, data_vals)\n",
    "    with open('Model_Script/Data/Data_cols_id_'+str(ID)+'.npy', 'wb') as f:\n",
    "        np.save(f, data_cols)\n",
    "    with open('Model_Script/Data/y_id_'+str(ID)+'.npy', 'wb') as f:\n",
    "        np.save(f, y)\n",
    "    if Norm:\n",
    "        un_norm_vals =  un_norm.to_numpy()\n",
    "        with open('Model_Script/Data/un_norm_vals_id_'+str(ID)+'.npy', 'wb') as f:\n",
    "            np.save(f, un_norm_vals)\n",
    "    \n",
    "    \n",
    "    # metadata & variable information \n",
    "    #print(database.metadata) \n",
    "    #print('-----------')\n",
    "    #print(database.variables) \n",
    "    if Norm: \n",
    "        return data_vals,data_cols, y, un_norm_vals\n",
    "    else:\n",
    "        return data_vals,data_cols, y\n",
    "    \n",
    "################################################################################################################## \n",
    "ID = 45\n",
    "\n",
    "Data_vals, Data_cols, yy = prep_data3(ID, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "88509e2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10714285714285714\n",
      "0.36\n",
      "0.24719101123595505\n",
      "0.0\n",
      "(0.25285714285714284, 0.24719101123595505)\n",
      "-------------------------\n",
      "0.13392857142857142\n",
      "0.16\n",
      "0.2808988764044944\n",
      "0.08571428571428572\n",
      "(0.02607142857142858, 0.1951845906902087)\n",
      "-------------------------\n",
      "0.24107142857142858\n",
      "0.2\n",
      "0.11235955056179775\n",
      "0.07142857142857142\n",
      "(0.041071428571428564, 0.040930979133226325)\n"
     ]
    }
   ],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n",
    "\n",
    "def MAX_group_ineq(Data_vals, y, vvars, Prot_feats, E=1):\n",
    "    '''finds max Delta y(I)'''\n",
    "    N = len(y)\n",
    "    E_behav = E\n",
    "    \n",
    "    Y_pos_index = np.array([i for i in range(N)])[[(i==1) for i in y]]\n",
    "    Y_neg_index = np.array([i for i in range(N)])[[(i==0) for i in y]]\n",
    "\n",
    "    Prot_feats_SetList = []\n",
    "    for feat in Prot_feats:\n",
    "        #get I_f^k 's\n",
    "        Prot_feats_SetList += [np.array([i for i in range(N)])[[ i[feat]==1  for i in Data_vals]]] #assuming the feature is binary, f_1\n",
    "        Prot_feats_SetList += [np.array([i for i in range(N)])[[ i[feat]==0  for i in Data_vals]]] #f_2\n",
    "\n",
    "    if Prot_feats: #if we include fairness constraints in the model\n",
    "        #get P_f^k 's\n",
    "        Pfks = []\n",
    "        for setlist in Prot_feats_SetList:\n",
    "            Pfks += [intersection( Y_pos_index , setlist )]\n",
    "        if (E_behav==1):\n",
    "            #get N_f^k 's\n",
    "            Nfks = []\n",
    "            for setlist in Prot_feats_SetList:\n",
    "                Nfks += [intersection( Y_neg_index , setlist )]\n",
    "    \n",
    "    cs=[]\n",
    "    for var in vvars:\n",
    "        if str(var[0])[0]=='c':\n",
    "            cs+=[var]\n",
    "            \n",
    "    maxxFP = 0\n",
    "    maxxFN = 0\n",
    "    \n",
    "    for feat in range(len(Prot_feats)):\n",
    "        print(sum(int(cs[i][1][0]) for i in Pfks[2*feat]   )/len(Pfks[2*feat]))\n",
    "        print(sum(int(cs[i][1][0]) for i in Pfks[2*feat+1]   )/len(Pfks[2*feat+1]))\n",
    "        curr = abs(sum(int(cs[i][1][0]) for i in Pfks[2*feat]   )/len(Pfks[2*feat])   -  sum(int(cs[i][1][0]) for i in Pfks[2*feat+1] )/len(Pfks[2*feat+1]))\n",
    "        if curr>maxxFP:\n",
    "            maxxFP=curr\n",
    "            \n",
    "        if E_behav==1:\n",
    "            print(sum(int(cs[i][1][0]) for i in Nfks[2*feat]   )/len(Nfks[2*feat]))\n",
    "            print(sum(int(cs[i][1][0]) for i in Nfks[2*feat+1]   )/len(Nfks[2*feat+1]))\n",
    "            curr2 = abs(sum(int(cs[i][1][0]) for i in Nfks[2*feat]   )/len(Nfks[2*feat])   -  sum(int(cs[i][1][0]) for i in Nfks[2*feat+1] )/len(Nfks[2*feat+1]))\n",
    "            if curr2>maxxFN:\n",
    "                maxxFN=curr2\n",
    "                \n",
    "                \n",
    "    return maxxFP, maxxFN\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "prot_feats = [1]\n",
    "with open('Model_script/Results/Vars_N296_A6_Clas1_B0 simple_F1.npy', 'rb') as f:\n",
    "        vvars1 = np.load(f,allow_pickle=True)\n",
    "with open('Model_script/Results/Vars_N296_A6_Clas1_B0 simple_F1_Fair0_bd10.05.npy', 'rb') as f:\n",
    "        vvars2 = np.load(f,allow_pickle=True)\n",
    "with open('Model_script/Results/Vars_N296_A6_Clas1_B0 simple_F1_Fair1_bd10.05.npy', 'rb') as f:\n",
    "        vvars3 = np.load(f,allow_pickle=True)\n",
    "        \n",
    "with open('Data_vals_id_'+str(45)+'.npy', 'rb') as f:\n",
    "        Data_vals = np.load(f,allow_pickle=True)\n",
    "with open('y_id_'+str(45)+'.npy', 'rb') as f:\n",
    "        y = np.load(f,allow_pickle=True)\n",
    "\n",
    "print(MAX_group_ineq(Data_vals, y, vvars1, prot_feats))\n",
    "print('-------------------------')\n",
    "print(MAX_group_ineq(Data_vals, y, vvars2, prot_feats, E=1))\n",
    "print('-------------------------')\n",
    "print(MAX_group_ineq(Data_vals, y, vvars3, prot_feats, E=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "347b0d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((oldpeak 10^1>=25.0))  |  ((chol>=267.0)&(oldpeak 10^1>=15.1))  |  ((Is sex = 1>=0.1)&(ca>=0.1))  |  ((thalach<=114.0))\n"
     ]
    }
   ],
   "source": [
    "with open('Model_script/Results/Ruleset_N296_A6_Clas1_B0 simple_F3.npy', 'rb') as f:\n",
    "        print(np.load(f,allow_pickle=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "64911480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classified(i):\n",
    "    return (((Data['ca'][i]>=0.1)&(Data['trestbps'][i]>=118.1)&(Data['thal'][i]!= 3))  |  ((Data['oldpeak'][i]>=2.41))  |  ((Data['exang' ][i]!=0)&(Data['cp'][i]==4))) \n",
    "\n",
    "[int(classified(i)) for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "7f8a78f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 <-- 0\n",
      "1 1 1 <-- 0\n",
      "2 1 1 <-- 0\n",
      "3 1 0     1\n",
      "4 0 0 <-- 0\n",
      "5 0 0 <-- 0\n",
      "6 1 1 <-- 0\n",
      "7 1 0     1\n",
      "8 1 1 <-- 0\n",
      "9 1 1 <-- 0\n",
      "10 0 0 <-- 0\n",
      "11 0 0 <-- 0\n",
      "12 1 1 <-- 0\n",
      "13 0 0 <-- 0\n",
      "14 0 0 <-- 0\n",
      "15 0 0 <-- 0\n",
      "16 0 1     1\n",
      "17 0 0 <-- 0\n",
      "18 0 0 <-- 0\n",
      "19 0 0 <-- 0\n",
      "20 0 0 <-- 0\n",
      "21 0 0 <-- 0\n",
      "22 0 1     1\n",
      "23 1 1 <-- 0\n",
      "24 1 1 <-- 0\n",
      "25 0 0 <-- 0\n",
      "26 0 0 <-- 0\n",
      "27 1 0     1\n",
      "28 0 0 <-- 0\n",
      "29 1 1 <-- 0\n",
      "30 0 0 <-- 0\n",
      "31 1 1 <-- 0\n",
      "32 0 1     1\n",
      "33 0 0 <-- 0\n",
      "34 0 0 <-- 0\n",
      "35 0 0 <-- 0\n",
      "36 1 1 <-- 0\n",
      "37 1 1 <-- 0\n",
      "38 1 1 <-- 0\n",
      "39 0 0 <-- 0\n",
      "40 1 1 <-- 0\n",
      "41 0 0 <-- 0\n",
      "42 0 0 <-- 0\n",
      "43 0 0 <-- 0\n",
      "44 0 1     1\n",
      "45 1 1 <-- 0\n",
      "46 0 0 <-- 0\n",
      "47 1 1 <-- 0\n",
      "48 0 0 <-- 0\n",
      "49 0 0 <-- 0\n",
      "50 0 0 <-- 0\n",
      "51 0 0 <-- 0\n",
      "52 0 1     1\n",
      "53 0 0 <-- 0\n",
      "54 1 1 <-- 0\n",
      "55 1 1 <-- 0\n",
      "56 1 1 <-- 0\n",
      "57 0 1     1\n",
      "58 0 0 <-- 0\n",
      "59 0 0 <-- 0\n",
      "60 1 1 <-- 0\n",
      "61 0 0 <-- 0\n",
      "62 1 1 <-- 0\n",
      "63 0 0 <-- 0\n",
      "64 1 1 <-- 0\n",
      "65 1 1 <-- 0\n",
      "66 1 1 <-- 0\n",
      "67 0 0 <-- 0\n",
      "68 1 1 <-- 0\n",
      "69 1 1 <-- 0\n",
      "70 0 0 <-- 0\n",
      "71 1 1 <-- 0\n",
      "72 1 1 <-- 0\n",
      "73 0 1     1\n",
      "74 0 1     1\n",
      "75 0 0 <-- 0\n",
      "76 1 1 <-- 0\n",
      "77 0 0 <-- 0\n",
      "78 0 0 <-- 0\n",
      "79 1 1 <-- 0\n",
      "80 1 0     1\n",
      "81 0 0 <-- 0\n",
      "82 0 0 <-- 0\n",
      "83 0 1     1\n",
      "84 0 0 <-- 0\n",
      "85 0 0 <-- 0\n",
      "86 0 0 <-- 0\n",
      "87 0 0 <-- 0\n",
      "88 0 0 <-- 0\n",
      "89 0 0 <-- 0\n",
      "90 1 1 <-- 0\n",
      "91 1 0     1\n",
      "92 0 0 <-- 0\n",
      "93 0 0 <-- 0\n",
      "94 1 1 <-- 0\n",
      "95 1 1 <-- 0\n",
      "96 1 1 <-- 0\n",
      "97 0 0 <-- 0\n",
      "98 0 0 <-- 0\n",
      "99 0 0 <-- 0\n",
      "100 0 0 <-- 0\n",
      "101 0 0 <-- 0\n",
      "102 0 0 <-- 0\n",
      "103 1 1 <-- 0\n",
      "104 0 0 <-- 0\n",
      "105 1 1 <-- 0\n",
      "106 1 1 <-- 0\n",
      "107 1 1 <-- 0\n",
      "108 0 1     1\n",
      "109 1 1 <-- 0\n",
      "110 1 1 <-- 0\n",
      "111 0 0 <-- 0\n",
      "112 1 1 <-- 0\n",
      "113 1 1 <-- 0\n",
      "114 0 0 <-- 0\n",
      "115 0 0 <-- 0\n",
      "116 0 0 <-- 0\n",
      "117 1 1 <-- 0\n",
      "118 1 1 <-- 0\n",
      "119 1 1 <-- 0\n",
      "120 1 1 <-- 0\n",
      "121 0 0 <-- 0\n",
      "122 1 1 <-- 0\n",
      "123 0 1     1\n",
      "124 0 0 <-- 0\n",
      "125 1 1 <-- 0\n",
      "126 1 1 <-- 0\n",
      "127 0 0 <-- 0\n",
      "128 0 0 <-- 0\n",
      "129 0 0 <-- 0\n",
      "130 0 0 <-- 0\n",
      "131 0 0 <-- 0\n",
      "132 1 0     1\n",
      "133 0 0 <-- 0\n",
      "134 0 0 <-- 0\n",
      "135 1 1 <-- 0\n",
      "136 1 1 <-- 0\n",
      "137 1 1 <-- 0\n",
      "138 0 0 <-- 0\n",
      "139 0 0 <-- 0\n",
      "140 0 1     1\n",
      "141 0 0 <-- 0\n",
      "142 0 1     1\n",
      "143 0 0 <-- 0\n",
      "144 0 1     1\n",
      "145 1 1 <-- 0\n",
      "146 0 0 <-- 0\n",
      "147 0 0 <-- 0\n",
      "148 0 0 <-- 0\n",
      "149 0 0 <-- 0\n",
      "150 0 0 <-- 0\n",
      "151 1 1 <-- 0\n",
      "152 1 1 <-- 0\n",
      "153 0 1     1\n",
      "154 1 1 <-- 0\n",
      "155 1 1 <-- 0\n",
      "156 1 1 <-- 0\n",
      "157 0 0 <-- 0\n",
      "158 0 0 <-- 0\n",
      "159 1 1 <-- 0\n",
      "160 0 0 <-- 0\n",
      "161 0 0 <-- 0\n",
      "162 0 0 <-- 0\n",
      "163 1 0     1\n",
      "164 0 0 <-- 0\n",
      "165 1 1 <-- 0\n",
      "166 0 0 <-- 0\n",
      "167 1 1 <-- 0\n",
      "168 1 0     1\n",
      "169 1 1 <-- 0\n",
      "170 0 0 <-- 0\n",
      "171 1 1 <-- 0\n",
      "172 1 1 <-- 0\n",
      "173 0 0 <-- 0\n",
      "174 1 1 <-- 0\n",
      "175 0 0 <-- 0\n",
      "176 0 0 <-- 0\n",
      "177 0 1     1\n",
      "178 1 1 <-- 0\n",
      "179 0 0 <-- 0\n",
      "180 1 0     1\n",
      "181 0 1     1\n",
      "182 0 0 <-- 0\n",
      "183 0 0 <-- 0\n",
      "184 1 1 <-- 0\n",
      "185 1 1 <-- 0\n",
      "186 1 1 <-- 0\n",
      "187 0 0 <-- 0\n",
      "188 1 1 <-- 0\n",
      "189 0 1     1\n",
      "190 0 0 <-- 0\n",
      "191 1 1 <-- 0\n",
      "192 0 0 <-- 0\n",
      "193 1 0     1\n",
      "194 0 0 <-- 0\n",
      "195 0 1     1\n",
      "196 0 0 <-- 0\n",
      "197 1 0     1\n",
      "198 1 0     1\n",
      "199 0 0 <-- 0\n",
      "200 0 0 <-- 0\n",
      "201 1 1 <-- 0\n",
      "202 1 1 <-- 0\n",
      "203 1 1 <-- 0\n",
      "204 0 0 <-- 0\n",
      "205 1 1 <-- 0\n",
      "206 0 0 <-- 0\n",
      "207 1 1 <-- 0\n",
      "208 0 0 <-- 0\n",
      "209 1 1 <-- 0\n",
      "210 0 1     1\n",
      "211 0 0 <-- 0\n",
      "212 0 0 <-- 0\n",
      "213 1 0     1\n",
      "214 0 0 <-- 0\n",
      "215 0 0 <-- 0\n",
      "216 0 0 <-- 0\n",
      "217 0 0 <-- 0\n",
      "218 0 0 <-- 0\n",
      "219 1 1 <-- 0\n",
      "220 1 1 <-- 0\n",
      "221 0 0 <-- 0\n",
      "222 0 0 <-- 0\n",
      "223 0 0 <-- 0\n",
      "224 1 1 <-- 0\n",
      "225 1 1 <-- 0\n",
      "226 0 0 <-- 0\n",
      "227 1 1 <-- 0\n",
      "228 0 1     1\n",
      "229 0 0 <-- 0\n",
      "230 0 0 <-- 0\n",
      "231 1 1 <-- 0\n",
      "232 1 1 <-- 0\n",
      "233 0 1     1\n",
      "234 0 0 <-- 0\n",
      "235 0 0 <-- 0\n",
      "236 0 0 <-- 0\n",
      "237 0 0 <-- 0\n",
      "238 0 0 <-- 0\n",
      "239 1 1 <-- 0\n",
      "240 0 0 <-- 0\n",
      "241 0 1     1\n",
      "242 0 1     1\n",
      "243 1 1 <-- 0\n",
      "244 1 1 <-- 0\n",
      "245 0 0 <-- 0\n",
      "246 1 0     1\n",
      "247 1 1 <-- 0\n",
      "248 1 0     1\n",
      "249 0 0 <-- 0\n",
      "250 0 0 <-- 0\n",
      "251 0 0 <-- 0\n",
      "252 0 0 <-- 0\n",
      "253 0 0 <-- 0\n",
      "254 0 0 <-- 0\n",
      "255 0 1     1\n",
      "256 0 0 <-- 0\n",
      "257 0 1     1\n",
      "258 0 0 <-- 0\n",
      "259 0 0 <-- 0\n",
      "260 1 1 <-- 0\n",
      "261 1 1 <-- 0\n",
      "262 1 1 <-- 0\n",
      "263 0 1     1\n",
      "264 0 0 <-- 0\n",
      "265 1 1 <-- 0\n",
      "266 0 0 <-- 0\n",
      "267 1 1 <-- 0\n",
      "268 0 0 <-- 0\n",
      "269 0 1     1\n",
      "270 0 0 <-- 0\n",
      "271 0 0 <-- 0\n",
      "272 0 0 <-- 0\n",
      "273 0 1     1\n",
      "274 0 0 <-- 0\n",
      "275 1 1 <-- 0\n",
      "276 0 0 <-- 0\n",
      "277 1 1 <-- 0\n",
      "278 0 0 <-- 0\n",
      "279 1 1 <-- 0\n",
      "280 1 1 <-- 0\n",
      "281 1 1 <-- 0\n",
      "282 0 0 <-- 0\n",
      "283 0 0 <-- 0\n",
      "284 0 1     1\n",
      "285 0 0 <-- 0\n",
      "286 1 1 <-- 0\n",
      "287 1 1 <-- 0\n",
      "288 1 1 <-- 0\n",
      "289 0 0 <-- 0\n",
      "290 1 1 <-- 0\n",
      "291 1 1 <-- 0\n",
      "292 0 1     1\n",
      "293 1 1 <-- 0\n",
      "294 1 1 <-- 0\n",
      "295 0 1     1\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "cnter = 0\n",
    "for i in range(N):\n",
    "    if int(classified(i))==y[i]:\n",
    "        cnter+=1\n",
    "        print(i, int(classified(i)), y[i], '<--', classifications[i][1])\n",
    "    else: \n",
    "        print(i, int(classified(i)), y[i], '   ', classifications[i][1])\n",
    "    \n",
    "print(cnter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e3b7aa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "2     67    1   4       120   229    0        2      129      1      2.6   \n",
      "8     63    1   4       130   254    0        2      147      0      1.4   \n",
      "9     53    1   4       140   203    1        2      155      1      3.1   \n",
      "12    56    1   3       130   256    1        2      142      1      0.6   \n",
      "16    48    1   2       110   229    0        0      168      0      1.0   \n",
      "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
      "287   63    1   4       140   187    0        2      144      1      4.0   \n",
      "290   59    1   4       164   176    1        2       90      0      1.0   \n",
      "291   57    0   4       140   241    0        0      123      1      0.2   \n",
      "293   68    1   4       144   193    1        0      141      0      3.4   \n",
      "294   57    1   4       130   131    0        0      115      1      1.2   \n",
      "\n",
      "     slope  ca  thal  \n",
      "2        2   2     7  \n",
      "8        2   1     7  \n",
      "9        3   0     7  \n",
      "12       2   1     6  \n",
      "16       3   0     7  \n",
      "..     ...  ..   ...  \n",
      "287      1   2     7  \n",
      "290      2   2     6  \n",
      "291      2   0     7  \n",
      "293      2   2     7  \n",
      "294      2   1     7  \n",
      "\n",
      "[97 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#True Positives\n",
    "TP = Data[[  ( ((Data['thal'][i]!=3)&(Data['cp'][i]!=1))  &  (y[i]==1)  ) for i in range(N)]]\n",
    "print(TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "8fed50ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0     63    1   1       145   233    1        2      150      0      2.3   \n",
      "3     37    1   3       130   250    0        0      187      0      3.5   \n",
      "4     41    0   2       130   204    0        2      172      0      1.4   \n",
      "5     56    1   2       120   236    0        0      178      0      0.8   \n",
      "7     57    0   4       120   354    0        0      163      1      0.6   \n",
      "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
      "276   47    1   3       130   253    0        0      179      0      0.0   \n",
      "278   35    1   2       122   192    0        0      174      0      0.0   \n",
      "283   56    1   2       120   240    0        0      169      0      0.0   \n",
      "285   55    0   2       132   342    0        0      166      0      1.2   \n",
      "289   41    1   2       120   157    0        0      182      0      0.0   \n",
      "\n",
      "     slope  ca  thal  \n",
      "0        3   0     6  \n",
      "3        3   0     3  \n",
      "4        1   0     3  \n",
      "5        1   0     3  \n",
      "7        1   0     3  \n",
      "..     ...  ..   ...  \n",
      "276      1   0     3  \n",
      "278      1   0     3  \n",
      "283      3   0     3  \n",
      "285      1   0     3  \n",
      "289      1   0     3  \n",
      "\n",
      "[134 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#True Negatives\n",
    "TN = Data[[(   ( (((Data['thal'][i]!=3)&(Data['cp'][i]!=1)))==False)  &  (y[i]==0)  )for i in range(N)]]\n",
    "print(TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ca832bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    }
   ],
   "source": [
    "print(len(TP)+len(TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "10b8fc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i  for i in range(len(y)) if y[i]==0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old copy of model just in case\n",
    "\n",
    "#Comment in case we dont need to import the packages\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import random \n",
    "#import sys #I hope we can use the sys package, because otherwise this doesnt work\n",
    "\n",
    "\n",
    "def Get_costs(ID, C_behav):     \n",
    "    if (ID==45):\n",
    "        #        age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope,  ca, thal\n",
    "        Costs =   [0,   0, 71,       20,    5,  30,      73,      10,    75,      72,    77, 100,   40] #ID = 45\n",
    "            \n",
    "        if (C_behav=='simple'):\n",
    "            Bundles = []\n",
    "        elif (C_behav=='complex'):\n",
    "            Bundles = [0,0,  1,       2,    3,   2,       1,       4,     1,       1,     1,   5,    2]\n",
    "        else: \n",
    "            print('you spelled something wrong in C_behav')\n",
    "            \n",
    "        return Costs, Bundles\n",
    "    \n",
    "    #do the other IDs later      \n",
    "        \n",
    "##################################################################################################################\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "def Model_model(Data_vals, Data_cols, y, alpha, ID=-1, Budget = 0, M_behav = 'same', C_behav = 'simple', Un_norm = np.array([]) , focus = 0, E_behav = 0, Prot_feats = [], Eq_Bd=0.05 ):\n",
    "    ''' Creates the MIP, optimizes it and gives you the resulting ruleset.\n",
    "    ----------------\n",
    "    Data_vals: Array with X data values\n",
    "    \n",
    "    Data_cols: Column names for X\n",
    "    \n",
    "    y:       List with obj data\n",
    "    \n",
    "    alpha:   Maximum number of bounds allowed\n",
    "    \n",
    "    ID:      The database id\n",
    "    \n",
    "    Budget:  Maximum budget allowed\n",
    "    \n",
    "    M_behav: same       --> M is computed at the begining (making it very large) and all Ms are the same\n",
    "             diff       --> M is computed per feature depending on a_j (option disabled)\n",
    "             \n",
    "    c_behav: simple     --> Each feature has independent costs\n",
    "             complex    --> Some features get discounted if selected together\n",
    "             \n",
    "    Un_norm: array outputed by the data prep function if you decide to normalize data; needed to turn it back to original scale\n",
    "    \n",
    "    focus:   Changes the MIPfocus, from 0 to 3, each modifies the branch&cut strategy for Gurobi. \n",
    "\n",
    "    E_behav   : 0  --> Equality of opportunity\n",
    "                1  --> Equality of opportunity and Equalized odds\n",
    "\n",
    "    Prot_feats: Protected features, as a list of column indexes, assume features are binary (sex=1 for ID=45, try that first)\n",
    "\n",
    "    Eq_Bd     : Max vialation of classifier, for the equality constraints\n",
    "    -----------------\n",
    "    Outputs: \n",
    "    The model variables that encode the bounds (a, b, s), the rectangles (r), and maybe more if you want\n",
    "    The ruleset as a code-ready string \n",
    "    The time it took and the objective it reached'''\n",
    "    \n",
    "    print('begin')\n",
    "    #define some parameters\n",
    "    N = len(Data_vals)    #number of points\n",
    "    d = len(Data_cols)    #number of features\n",
    "    m = 2*alpha +1        #small m for the inequality-related indicators\n",
    "    Upsi = max(y)         #Number of classes\n",
    "\n",
    "    if (Budget != 0):\n",
    "        if (ID == -1):\n",
    "            Costs = [1]*d\n",
    "        else:\n",
    "            Costs, Bundles = Get_costs(ID, C_behav)\n",
    "\n",
    "    if (M_behav == 'same'):\n",
    "        M= 2*Data_vals.max() + 2      \n",
    "    \n",
    "    Data_vals = np.asfarray(Data_vals) #Change all columns to float and find the precision of each column   \n",
    "     \n",
    "    e = []\n",
    "    for i in range(len(Data_cols)):\n",
    "        buffer = []\n",
    "        for j in range(len(Data_vals)):\n",
    "            buffer += [len(str(Data_vals[j][i]).split('.')[1])]\n",
    "        e+=[10**-(max(buffer)+1)]\n",
    "   \n",
    "        \n",
    "    #separate indices of y= 1s and 0s \n",
    "    if (Upsi==1):\n",
    "        Y_pos_index = np.array([i for i in range(N)])[[(i==1) for i in y]]\n",
    "        Y_neg_index = np.array([i for i in range(N)])[[(i==0) for i in y]]\n",
    "\n",
    "        Prot_feats_SetList = []\n",
    "        for feat in Prot_feats:\n",
    "            #get I_f^k 's\n",
    "            Prot_feats_SetList += [np.array([i for i in range(N)])[[ i[feat]==1  for i in Data_vals]]] #assuming the feature is binary, f_1\n",
    "            Prot_feats_SetList += [np.array([i for i in range(N)])[[ i[feat]==0  for i in Data_vals]]] #f_2\n",
    "\n",
    "        if Prot_feats: #if we include fairness constraints in the model\n",
    "            #get P_f^k 's\n",
    "            Pfks = []\n",
    "            for setlist in Prot_feats_SetList:\n",
    "                Pfks += [intersection( Y_pos_index , setlist )]\n",
    "            if (E_behav==1):\n",
    "                #get N_f^k 's\n",
    "                Nfks = []\n",
    "                for setlist in Prot_feats_SetList:\n",
    "                    Nfks += [intersection( Y_neg_index , setlist )]\n",
    "    elif (Upsi>=2):\n",
    "        Y_pos_index = np.array([i for i in range(N)])[[(i>=1) for i in y]]\n",
    "        Y_neg_index = np.array([i for i in range(N)])[[(i==0) for i in y]]\n",
    "\n",
    "        Pos_Classes = []\n",
    "        for val in range(Upsi):\n",
    "            Pos_Classes += [[val, np.array([i for i in range(N)])[[(i==val+1) for i in y]]]]\n",
    "        print(Pos_Classes)\n",
    "\n",
    "\n",
    "    print('creating vars')\n",
    "    #create the model\n",
    "    Model_1 = gp.Model('model1')\n",
    "\n",
    "    b = Model_1.addMVar((alpha), lb=0, ub=[float('inf')]*alpha, vtype=GRB.CONTINUOUS, name='b')    #b_(bnd)\n",
    "    a = Model_1.addMVar((alpha,d), vtype=GRB.BINARY, name='a')                                     #a_(bnd, dim)\n",
    "    s = Model_1.addMVar((alpha), vtype=GRB.BINARY, name='s')                                       #s_(bnd)\n",
    "    z = Model_1.addMVar((N, alpha), vtype=GRB.BINARY, name='z')                                    #z_(point, bnd)\n",
    "    r = Model_1.addMVar((alpha, alpha), vtype=GRB.BINARY, name='r')                                #r_(rec, bnd)\n",
    "    w = Model_1.addMVar((N, alpha), vtype=GRB.BINARY, name='w')                                    #w_(point, rec)\n",
    "    h = Model_1.addMVar((N, alpha, alpha), vtype=GRB.BINARY, name='h')                             #h_(point, rec, bnd)\n",
    "    g = Model_1.addMVar((alpha), vtype=GRB.BINARY, name='g')                                       #g_(rec)\n",
    "    c = Model_1.addMVar((N), vtype=GRB.BINARY, name='c')                                           #c_(point)\n",
    "\n",
    "    \n",
    "    #Model_1.addConstrs( (b[j] == 0.5 for j in range(alpha)), name='false_b_con')\n",
    "\n",
    "    \n",
    "    Model_1.addConstrs( (sum(a[j]) == 1 for j in range(alpha)), name='a_con')\n",
    "\n",
    "    Model_1.addConstrs( (sum([r[l][j] for l in range(alpha)]) <= 1 for j in range(alpha)), name='r_con1')\n",
    "\n",
    "    Model_1.addConstrs( (r[l][j]       >= h[i][l][j]           for i in range(N) for j in range(alpha) for l in range(alpha)), name='h_con1')\n",
    "    Model_1.addConstrs( (z[i][j]       >= h[i][l][j]           for i in range(N) for j in range(alpha) for l in range(alpha)), name='h_con2')\n",
    "    Model_1.addConstrs( (h[i][l][j] +1 >= r[l][j] + z[i][j]    for i in range(N) for j in range(alpha) for l in range(alpha)), name='h_con3')\n",
    "\n",
    "    Model_1.addConstrs( (sum(r[l]) <= g[l]*alpha   for l in range(alpha)), name='g_conr')\n",
    "    Model_1.addConstrs( (sum(r[l]) >= g[l]         for l in range(alpha)), name='g_conl')\n",
    "\n",
    "    Model_1.addConstrs( (g[l] >= w[i][l]           for i in Y_neg_index for l in range(alpha)), name='w_con1')\n",
    "    Model_1.addConstrs( (g[l] >= 1-w[i][l]         for i in Y_pos_index for l in range(alpha)), name='w_con1')\n",
    "    \n",
    "    Model_1.addConstrs( (sum(r[l])-sum(h[i][l]) >= w[i][l]           - m*(1-g[l])   for i in Y_pos_index for l in range(alpha)), name='w_con2l')\n",
    "    Model_1.addConstrs( (sum(r[l])-sum(h[i][l]) <= w[i][l]*alpha     + m*(1-g[l])   for i in Y_pos_index for l in range(alpha)), name='w_con2r')\n",
    "    Model_1.addConstrs( (sum(h[i][l])           >= (1-w[i][l])       - m*(1-g[l])   for i in Y_neg_index for l in range(alpha)), name='w_con3l')\n",
    "    Model_1.addConstrs( (sum(h[i][l])           <= (1-w[i][l])*alpha + m*(1-g[l])   for i in Y_neg_index for l in range(alpha)), name='w_con3r')\n",
    "    \n",
    "    Model_1.addConstrs( (sum(w[i])         <= alpha*c[i]       for i in Y_neg_index ), name='c_con2r')\n",
    "    Model_1.addConstrs( (sum(w[i])         >= c[i]             for i in Y_neg_index ), name='c_con2l')\n",
    "\n",
    "    if (Upsi>=2):\n",
    "        colors = Model_1.addMVar((alpha,Upsi), vtype=GRB.BINARY, name='color')                     #colors_(rec, col)\n",
    "        zet    = Model_1.addMVar((N,alpha), vtype=GRB.BINARY, name='zet')                          #zet_(pnt, rec)\n",
    "\n",
    "        Model_1.addConstrs( (sum(colors[l]) == 1 for l in range(alpha)), name='color_con')\n",
    "\n",
    "        for clas in range(Upsi): #index is -1 from label\n",
    "            curr_class = Pos_Classes[clas][1]\n",
    "            curr_col   = Pos_Classes[clas][0]\n",
    "            Model_1.addConstrs( (1-w[i][l]           >= 1 - zet[i][l]                   for i in curr_class for l in range(alpha)), name='zet_con1')\n",
    "            Model_1.addConstrs( (colors[l][curr_col] >= 1 - zet[i][l]                   for i in curr_class for l in range(alpha)), name='zet_con2')\n",
    "            Model_1.addConstrs( (2 - zet[i][l]       >= 1-w[i][l] + colors[l][curr_col] for i in curr_class for l in range(alpha)), name='zet_con3')\n",
    "\n",
    "        Model_1.addConstrs( (alpha - sum(zet[i]) <= alpha*(1-c[i])   for i in Y_pos_index ), name='c_con1r')\n",
    "        Model_1.addConstrs( (alpha - sum(zet[i]) >= 1-c[i]           for i in Y_pos_index ), name='c_con1l')\n",
    "\n",
    "    elif (Upsi==1):\n",
    "        Model_1.addConstrs( (alpha - sum(w[i]) <= alpha*(1-c[i])   for i in Y_pos_index ), name='c_con1r')\n",
    "        Model_1.addConstrs( (alpha - sum(w[i]) >= 1-c[i]           for i in Y_pos_index ), name='c_con1l')\n",
    "    \n",
    "    \n",
    "    if (M_behav=='same'):\n",
    "        #                     b   -  ...M(1-z)... -  ...2M(s)... +          ........e........           <=         ............ax............\n",
    "        Model_1.addConstrs( (b[j] - M*(1-z[i][j]) - 2*M*(s[j])   + sum(a[j][k]*e[k] for k in range(d))  <= sum(a[j][k]*Data_vals[i][k] for k in range(d))        for i in Y_neg_index for j in range(alpha)), name='z_con1l')\n",
    "        Model_1.addConstrs( (b[j] - M*z[i][j]     - 2*M*(1-s[j])                                        <= sum(a[j][k]*Data_vals[i][k] for k in range(d))        for i in Y_neg_index for j in range(alpha)), name='z_con2l')\n",
    "        Model_1.addConstrs( (b[j] - M*z[i][j]     - 2*M*(s[j])   + sum(a[j][k]*e[k] for k in range(d))  <= sum(a[j][k]*Data_vals[i][k] for k in range(d))        for i in Y_pos_index for j in range(alpha)), name='z_con3l')\n",
    "        Model_1.addConstrs( (b[j] - M*(1-z[i][j]) - 2*M*(1-s[j])                                        <= sum(a[j][k]*Data_vals[i][k] for k in range(d))        for i in Y_pos_index for j in range(alpha)), name='z_con4l')\n",
    "        \n",
    "        Model_1.addConstrs( (sum(a[j][k]*Data_vals[i][k] for k in range(d)) <= b[j] + M*z[i][j]     + 2*M*(s[j])                                                 for i in Y_neg_index for j in range(alpha)), name='z_con1r')\n",
    "        Model_1.addConstrs( (sum(a[j][k]*Data_vals[i][k] for k in range(d)) <= b[j] + M*(1-z[i][j]) + 2*M*(1-s[j]) - sum(a[j][k]*e[k] for k in range(d))         for i in Y_neg_index for j in range(alpha)), name='z_con2r')\n",
    "        Model_1.addConstrs( (sum(a[j][k]*Data_vals[i][k] for k in range(d)) <= b[j] + M*(1-z[i][j]) + 2*M*(s[j])                                                 for i in Y_pos_index for j in range(alpha)), name='z_con3r')\n",
    "        Model_1.addConstrs( (sum(a[j][k]*Data_vals[i][k] for k in range(d)) <= b[j] + M*z[i][j]     + 2*M*(1-s[j]) - sum(a[j][k]*e[k] for k in range(d))         for i in Y_pos_index for j in range(alpha)), name='z_con4r')\n",
    "    \n",
    "    if (Budget != 0):\n",
    "        q = Model_1.addMVar((d), vtype=GRB.BINARY, name='q')                                       #q_(dim)\n",
    "        Model_1.addConstrs( (    sum([a[j][k] for j in range(alpha)])      <= alpha*q[k]       for k in range(d) ), name='q_con1r')\n",
    "        Model_1.addConstrs( (    sum([a[j][k] for j in range(alpha)])      >= q[k]             for k in range(d) ), name='q_con1l')\n",
    "        \n",
    "        if (C_behav=='simple'):\n",
    "            print('simple budget constrs ativated')\n",
    "            Model_1.addConstr(  sum( q[k]*Costs[k] for k in range(d)) <= Budget , name='Budget_con')\n",
    "        \n",
    "        elif (C_behav=='complex'):\n",
    "            print('complex budget constrs ativated')\n",
    "            num_bundl = max(Bundles)+1                  #number of distinct bundles\n",
    "            Index = np.array([i for i in range(d)])     #Column indices\n",
    "            bundl_sets = []                             #Will store the column indices that belong to the same bundle\n",
    "            gammas = []                                 #will store the shared cost of each bundle set\n",
    "            \n",
    "            for beta in range(num_bundl): #separates the tests in bundles\n",
    "                bundl_sets += [list(Index[[Bundles[i] == beta for i in range(d)]])]\n",
    "\n",
    "            for sett in bundl_sets: #gets the common cost and updates the Costs to reflect only the extra charge\n",
    "                costs_in_set = []\n",
    "                for ind in sett:\n",
    "                    costs_in_set += [Costs[ind]]\n",
    "                gamma = min(costs_in_set)\n",
    "                gammas += [gamma]\n",
    "                for ind in sett:\n",
    "                    Costs[ind] -= gamma\n",
    "                    \n",
    "            beta = Model_1.addMVar((num_bundl), vtype=GRB.BINARY, name='beta')                  #beta_(#OfBundles)\n",
    "            \n",
    "            Model_1.addConstrs( (    sum([q[k] for k in bundl_sets[set_ind]])      <= len(bundl_sets[set_ind])*beta[set_ind]       for set_ind in range(num_bundl) ), name='beta_con1r')\n",
    "            Model_1.addConstrs( (    sum([q[k] for k in bundl_sets[set_ind]])      >= beta[set_ind]                                for set_ind in range(num_bundl) ), name='beta_con1l')\n",
    "            Model_1.addConstr(  sum( q[k]*Costs[k] for k in range(d)) + sum(beta[s]*gammas[s] for s in range(num_bundl)) <= Budget , name='Budget_con')\n",
    "        else:\n",
    "            print('something went wrong in the budget constraints')\n",
    "            \n",
    "    if Prot_feats:\n",
    "        epsilon = Eq_Bd #maximum violation of classifier\n",
    "        for feat in range(len(Prot_feats)):\n",
    "            Model_1.addConstr(  sum(c[i] for i in Pfks[2*feat]   )/len(Pfks[2*feat])   -  sum(c[i] for i in Pfks[2*feat+1] )/len(Pfks[2*feat+1]) <= epsilon , name='FN_conl')\n",
    "            Model_1.addConstr(  sum(c[i] for i in Pfks[2*feat+1] )/len(Pfks[2*feat+1]) -  sum(c[i] for i in Pfks[2*feat]   )/len(Pfks[2*feat])   <= epsilon , name='FN_conr')\n",
    "            if (E_behav==1):\n",
    "                Model_1.addConstr(  sum(c[i] for i in Nfks[2*feat]   )/len(Nfks[2*feat])   -  sum(c[i] for i in Nfks[2*feat+1] )/len(Nfks[2*feat+1]) <= epsilon , name='FP_conl')\n",
    "                Model_1.addConstr(  sum(c[i] for i in Nfks[2*feat+1] )/len(Nfks[2*feat+1]) -  sum(c[i] for i in Nfks[2*feat]   )/len(Nfks[2*feat])   <= epsilon , name='FP_conr')\n",
    "               \n",
    "    \n",
    "    #Parameters:\n",
    "    Model_1.Params.MIPFocus = focus\n",
    "    #Model_1.params.MIPGap = 0.10\n",
    "    Model_1.Params.timelimit = 9600\n",
    "    #Model_1.Params.DisplayInterval = 120\n",
    "    #Model_1.Params.OutputFlag = 0\n",
    "    #Model_1.params.Logfile = 'Results/log' + 'N'+str(len(Data_vals))+'_A'+str(alpha)+'_B'+str(Budget)+' ' +C_behav +'_F'+str(focus)\n",
    "    \n",
    "    Model_1.setObjective(sum((1-c[i]) for i in range(N)), GRB.MAXIMIZE)\n",
    "    \n",
    "    print('Optimizing: N'+str(len(Data_vals))+'_A'+str(alpha)+'_B'+str(Budget)+' ' +C_behav +'_F'+str(focus))\n",
    "    #compute the solution\n",
    "    Model_1.optimize()\n",
    "    #Model_1.write(\"debug2.lp\")\n",
    "    print('Done optimizing: N'+str(len(Data_vals))+'_A'+str(alpha)+'_B'+str(Budget)+' ' +C_behav +'_F'+str(focus))\n",
    "    #print the score and the ruleset\n",
    "    print('---SOLUTION---')\n",
    "    print('Objective: %g' % Model_1.ObjVal)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('---Ruleset---')\n",
    "    \n",
    "    or_cntr = 0\n",
    "    and_cntrs = [0]*alpha\n",
    "    \n",
    "    for l in range(alpha):              #On every rectangle\n",
    "        if g[l].X>0.5:                  #check if non-empty\n",
    "            or_cntr += 1                #count how many\n",
    "            for j in range(alpha):      #On each of those rectangles \n",
    "                if r[l][j].X>0.5:       #count how many bounds\n",
    "                    and_cntrs[l] += 1\n",
    "            \n",
    "    ruleset_list = '' \n",
    "    for l in range(alpha):\n",
    "        if g[l].X>0.5:                  #on every not empty rectangle\n",
    "            if (Upsi>=2):\n",
    "                rec_class = np.array([i for i in range(1, Upsi+1)])[[ colors[l][val].X==1 for val in range(Upsi)]]\n",
    "                ruleset_list += '(y=' +str(rec_class[0]) + ') & ('\n",
    "            else:\n",
    "                ruleset_list += '('\n",
    "\n",
    "            for j in range(alpha):\n",
    "                if r[l][j].X>0.5:       #on every bound where r=1 in this rectangle  \n",
    "                    for k in range(d):\n",
    "                        if a[j][k].X >0.5:       #find feature\n",
    "                            feat = Data_cols[k]\n",
    "                            \n",
    "                    #select bound\n",
    "                    if (not Un_norm.size == 0):                                             #if we need to un-normalize\n",
    "                        bd = b[j].X*Un_norm[0][k] + Un_norm[1][k]\n",
    "                    else:\n",
    "                        bd = b[j].X\n",
    "                        \n",
    "                    if s[j].X>0.5:                                                     #find direction\n",
    "                        print(str(feat) + ' >= ' + str(bd) + ' & ')                    #print inequality\n",
    "                        ruleset_list += '(' + str(feat) + ' >= ' + str(bd) + ')'\n",
    "                    elif s[j].X<0.5:\n",
    "                        print(str(feat) + ' <= ' + str(bd) + ' & ')\n",
    "                        ruleset_list += '(' + str(feat) + ' <= ' + str(bd) + ')'\n",
    "                        \n",
    "                    if (and_cntrs[l]-1 > 0):\n",
    "                        ruleset_list += '&'\n",
    "                        and_cntrs[l] += -1\n",
    "                    \n",
    "            print('OR')\n",
    "            ruleset_list += ')'\n",
    "            if (or_cntr-1 > 0):\n",
    "                ruleset_list += '  |  '\n",
    "                or_cntr += -1\n",
    "      \n",
    "    #Model_1.write(\"debug2.lp\")\n",
    "    \n",
    "    vvars = []\n",
    "    for v in Model_1.getVars():\n",
    "        if str(v.varname)[0] in ['a', 'b', 's', 'r', 'z','w', 'c']:\n",
    "            vvars += [[v.varname, v.X]]\n",
    "\n",
    "    '''if Prot_feats:\n",
    "        name_of_file = '_N'+str(len(Data_vals))+'_A'+str(alpha)+'_Clas' + str(Upsi)+'_B'+str(Budget)+' ' +C_behav +'_F'+str(focus)+'_Fair'+str(E_behav)+ '_bd1' + str(Eq_Bd) +'.npy'\n",
    "    else:\n",
    "        name_of_file = '_N'+str(len(Data_vals))+'_A'+str(alpha)+'_Clas' + str(Upsi)+'_B'+str(Budget)+' ' +C_behav +'_F'+str(focus)+'.npy'\n",
    "\n",
    "    with open('Results/Ruleset'+ name_of_file, 'wb') as f:\n",
    "        np.save(f, ruleset_list)\n",
    "    with open('Results/TimeObj'+ name_of_file, 'wb') as f:\n",
    "        np.save(f, np.array([Model_1.Runtime, Model_1.ObjVal]) )\n",
    "    with open('Results/Vars'+ name_of_file, 'wb') as f:\n",
    "        np.save(f, vvars)'''\n",
    "    \n",
    "    return ruleset_list, np.array([Model_1.Runtime, Model_1.ObjVal]), vvars\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "def Random_data_gen(length, dim, Upsi = 2):\n",
    "    '''length = number of points; dim = number of features'''\n",
    "\n",
    "    points = np.random.rand(length,dim)\n",
    "    for i in range(length):\n",
    "        for j in range(dim):\n",
    "            points[i][j] = round(points[i][j], 3)\n",
    "    val = np.random.randint(Upsi, size=(length))\n",
    "    return points, val\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#Read sys inputs\n",
    "length = 20# int(sys.argv[1])  #-1 for ID=45, any other number for randomly generated data of that size\n",
    "alpha =  0# int(sys.argv[2])  #number of inequs\n",
    "Budgt =  0# int(sys.argv[3])  #0 to disable budget constraints, any other number to use them\n",
    "B_behav= 0# sys.argv[4]       #'simple' or 'complex' for both behaviours\n",
    "Focs =   0# int(sys.argv[5])  #from 0 to 4\n",
    "\n",
    "if (length==-1): \n",
    "    IDD=45\n",
    "    with open('Data/Data_vals_id_'+str(IDD)+'.npy', 'rb') as f:\n",
    "        Data_vals = np.load(f,allow_pickle=True)\n",
    "    with open('Data/Data_cols_id_'+str(IDD)+'.npy', 'rb') as f:\n",
    "        Data_cols = np.load(f,allow_pickle=True)\n",
    "    with open('Data/y_id_'+str(IDD)+'.npy', 'rb') as f:\n",
    "        y = np.load(f,allow_pickle=True)\n",
    "    with open('Data/un_norm_vals_id_'+str(IDD)+'.npy', 'rb') as f:\n",
    "        un_norm_vals = np.load(f,allow_pickle=True)\n",
    "    \n",
    "    #Model_model(Data_vals, Data_cols, y, alpha, ID=IDD, Un_norm = un_norm_vals ,Budget = Budgt, C_behav = B_behav,  focus = Focs )\n",
    "\n",
    "else: #if we want random data, (to compare MIP focuses) then we need to use the same data for all 4 tests, sooooo we have to do them back to back\n",
    "    IDD=-1\n",
    "    Data_vals, y = Random_data_gen(length, 3, Upsi = 3)\n",
    "    Data_cols = ['x'*(i+1) for i in range(3)]\n",
    "    un_norm_vals = np.array([])\n",
    "\n",
    "    Data_vals = np.array([[0.1,0] ,[0.2,0], [0.3,0],[0.4,0]])\n",
    "    y= [2,0,2,0]\n",
    "    Data_cols = ['xx', 'yy']\n",
    "\n",
    "    rule, metrics, variables = Model_model(Data_vals, Data_cols, y, 4, focus = 2 )\n",
    "    #Model_model(Data_vals, Data_cols, y, alpha, ID=IDD, Un_norm = un_norm_vals ,Budget = Budgt, C_behav = B_behav,  focus = 1 )\n",
    "    #Model_model(Data_vals, Data_cols, y, alpha, ID=IDD, Un_norm = un_norm_vals ,Budget = Budgt, C_behav = B_behav,  focus = 2 )\n",
    "    #Model_model(Data_vals, Data_cols, y, alpha, ID=IDD, Un_norm = un_norm_vals ,Budget = Budgt, C_behav = B_behav,  focus = 3 )\n",
    "\n",
    "\n",
    "#Model_model(Data_vals, Data_cols, y, 6, ID = IDD, Un_norm = un_norm_vals, focus=2)   #Normal\n",
    "#Model_model(Data_vals, Data_cols, y, 6, ID = IDD, Un_norm = un_norm_vals, focus=2, E_behav = 0, Prot_feats = [1], Eq_Bd=0.05 ) \n",
    "#Model_model(Data_vals, Data_cols, y, 6, ID = IDD, Un_norm = un_norm_vals, focus=2, E_behav = 1, Prot_feats = [1], Eq_Bd=0.05 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D(Data, vals, ruleset):\n",
    "    ''' Plots the 2D rectangles, bla, bla '''\n",
    "\n",
    "    length = len(Data)\n",
    "    \n",
    "    dim = np.linspace(0,1,1000)\n",
    "    xx,yy = np.meshgrid(dim,dim)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for i in range(length):\n",
    "        plt.text(Data.iloc[i][0],Data.iloc[i][1],vals[i], ha=\"center\", va=\"center\")\n",
    "    plt.imshow(( eval(ruleset)   ).astype(int), extent=(0,1,0,1),origin=\"lower\", cmap=\"Greys\", alpha = 0.4)\n",
    "    \n",
    "    plt.title(\"Example of optimization using \" + str(alpha) + \" bounds and \" + str(length) + \"random points.\")\n",
    "    plt.xlabel(\"Age (Normalized)\")\n",
    "    plt.ylabel(\"Resting bpm (Normalized)\")\n",
    "\n",
    "    plt.savefig('2D_example')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
